{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1gzSeo8rXVhrTvQ5zDRaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vera-pro/ArtDATIS_NER_evaluation/blob/main/Evaluate_WikiNEuRal_on_a_sample_of_typed_documents_(semi_manual%2C_interactive).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qSm0XbwSZ_Bp"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import seaborn as sns\n",
        "\n",
        "def visualise(text, preds):\n",
        "    ## Step 1: adding entities\n",
        "    entities = []\n",
        "    nlp = spacy.blank(\"nl\")  # it should work with any language\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    ner_map = {} ## NB: our ner_map is reversed compared to the example\n",
        "    cur_type = ''\n",
        "    cur_start, cur_end = 0, 0\n",
        "    false_positives = []\n",
        "\n",
        "    for pred in preds: \n",
        "        ent = pred['entity']\n",
        "        if ent.startswith('B') or pred['start'] > cur_end+1: ## a dirty hack in case it failed to predict 'B'\n",
        "            ## Adding the previous entity if it's not empty\n",
        "            if cur_type != '':\n",
        "                char_span = doc.char_span(cur_start, cur_end, cur_type)\n",
        "                if char_span:\n",
        "                    entities.append(char_span)\n",
        "                else:\n",
        "                    false_positives.append((cur_start, cur_end, cur_type))\n",
        "\n",
        "            ## Processing the new entity\n",
        "            cur_type = ent[2:]\n",
        "            if cur_type not in ner_map: ## it's only 'B' in the example\n",
        "                ner_map[cur_type] = len(ner_map)+1\n",
        "            cur_start = pred['start']\n",
        "            cur_end = pred['end']\n",
        "        else: ## there's only 'B' and 'I', 'O' is not included\n",
        "            cur_end = pred['end']\n",
        "\n",
        "    ## Adding the last one\n",
        "    if cur_type != '':\n",
        "        char_span = doc.char_span(cur_start, cur_end, cur_type)\n",
        "        if char_span:\n",
        "            entities.append(char_span)\n",
        "        else:\n",
        "            false_positives.append((cur_start, cur_end, cur_type))\n",
        "            \n",
        "    doc.ents = entities\n",
        "    \n",
        "    ## Step 2: visualising \n",
        "    colours = sns.color_palette(\"Set2\", len(ner_map)).as_hex()\n",
        "    options = {\"ents\": list(ner_map.keys()),\n",
        "               \"colors\": {ent: colours[ner_map[ent]-1] for ent in ner_map.keys()}\n",
        "              }\n",
        "\n",
        "    displacy_html = displacy.render(doc, style=\"ent\", options=options)\n",
        "    return false_positives"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "data = pickle.load(open('ner_evaluation_typed_samples.p','rb'))"
      ],
      "metadata": {
        "id": "DrbYSrK3aW2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in data: \n",
        "    if 'false_positives' in entry:\n",
        "        continue # already processed\n",
        "    false_positives = visualise(entry['text'],entry['ner'])\n",
        "    false_negatives = []\n",
        "    \n",
        "    mention = ''\n",
        "    cur_start = 0\n",
        "    print('==============')\n",
        "    print(\"Are there any entities that we've missed?\")\n",
        "    print(\"Please enter them one by one: copy-paste the mentions from the text\")\n",
        "    print(\"in the order that they appear in the text\")\n",
        "    while mention != 'X':\n",
        "        mention = input(\"Copy-paste the next entity or type \\\"X\\\" to finish, then press enter\")\n",
        "        start = text[cur_start:].find(mention)\n",
        "        false_negatives.append((start, start+len(mention), 'ADDED'))\n",
        "        cur_start = start\n",
        "        \n",
        "    notes = input(\"Do you have any comments about this text? Please type here and press enter\")\n",
        "    \n",
        "    entry.update({'false_positives': false_positives,\n",
        "                 'false_negatives':false_negatives,\n",
        "                 'notes': notes})\n",
        "    pickle.dump(data, open('ner_evaluation_typed_samples.p','wb'))"
      ],
      "metadata": {
        "id": "TeeQHsadcKXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}